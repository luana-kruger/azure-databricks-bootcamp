# Desafio de Projeto 3: An√°lise de Dados com Notebooks no Azure Databricks

Este projeto foi desenvolvido como parte do bootcamp **Microsoft AI for Tech - Azure Databricks**, com base no m√≥dulo pr√°tico [Explorar o Azure Databricks](https://learn.microsoft.com/pt-br/training/modules/explore-azure-databricks/) do Microsoft Learn.

## üéØ Objetivo

O objetivo √© provisionar um ambiente completo no **Azure Databricks**, criar um **cluster de processamento Spark**, carregar e explorar dados utilizando **notebooks**, realizar visualiza√ß√µes e aplicar consultas com **SQL** e **PySpark**.



## üõ†Ô∏è Etapas do Projeto

### 1. Provisionamento do Workspace no Azure Databricks

O primeiro passo consiste na cria√ß√£o de um workspace do Azure Databricks diretamente pelo portal do Azure.

- Acesse o portal: [https://portal.azure.com](https://portal.azure.com)
- Crie um recurso do tipo **Azure Databricks** com as seguintes configura√ß√µes:
  - **Assinatura:** Selecione sua assinatura do Azure (nesse caso √© a Avali√ß√£o Gratuita criada no Projeto 1)
  - **Grupo de recursos:** `rg-msl-dio`
  - **Nome do Workspace:** `databricks-msl-dio`
  - **Regi√£o:** East US 2
  - **Tipo de pre√ßo:** Avalia√ß√£o gratuita (14 dias)
  - **Grupo de recursos gerenciados:** `databricks-msl-dio-managed`
  - **Marcas (tags):** Nome: `DIO` / Valor: `databricks-msl`

Ap√≥s revisar as configura√ß√µes, selecione **Revisar + Criar** e aguarde a conclus√£o da implanta√ß√£o. 

<p align="center">
<img src="images/criar-workspace-databricks.png" alt="infobox" width="60%" height="60%"> 
</p>



### 2. Cria√ß√£o do Cluster

O Azure Databricks utiliza clusters Apache Spark para o processamento distribu√≠do de dados. Nesta etapa, ser√° criado um cluster de n√≥ √∫nico para reduzir os recursos utilizados.

- Acesse o grupo de recursos `rg-msl-dio` e abra o workspace `databricks-msl-dio`.
- Clique em **Iniciar o Workspace** para abrir a interface do Databricks em nova aba.

<p align="center">
<img src="images/iniciar-workspace.png" alt="infobox" width="60%" height="60%"> 
</p>

- No menu lateral esquerdo, clique em **(+) Novo** e selecione **Cluster** (pode estar dentro do submenu "Mais").
- Preencha as seguintes configura√ß√µes:
  - **Nome do Cluster:** `msl-dio-cluster`
  - **Pol√≠tica:** Sem restri√ß√µes
  - **Modo de Cluster:** N√≥ √∫nico
  - **Modo de Acesso:** Usu√°rio √∫nico
  - **Vers√£o do Databricks Runtime:** 13.3 LTS (Spark 3.4.1, Scala 2.12) ou superior
  - **Acelera√ß√£o Photon:** Ativada
  - **Tipo de n√≥:** `Standard_D4s_v3` (compat√≠vel com a regi√£o East US 2 selecionada na cria√ß√£o do workspace do passo anterior)
  - **Encerrar ap√≥s:** 60 minutos de inatividade

Aguarde a cria√ß√£o do cluster, o que pode levar alguns minutos.

<p align="center">
<img src="images/cluster-azure-databricks.png" alt="infobox" width="60%" height="60%"> 
</p>



### 3. Carregamento dos Dados

Com o cluster criado, ser√° feito o upload de um arquivo CSV contendo informa√ß√µes de produtos.

- Baixe o arquivo [products.csv](https://raw.githubusercontent.com/MicrosoftLearning/mslearn-databricks/main/data/products.csv) para o seu computador.
- No menu lateral do Databricks, clique em **(+) Novo** > **Adicionar ou carregar dados**.
- Selecione **Criar ou modificar tabela** e envie o arquivo `products.csv`.

Na tela de cria√ß√£o da tabela, selecione o cluster ativo no canto superior direito, escolha o cat√°logo `hive_metastore` e o esquema padr√£o. Nomeie a tabela como `products`.

<p align="center">
<img src="images/criar-tabela.png" alt="infobox" width="60%" height="60%"> 
</p>



### 4. Cria√ß√£o do Notebook

Ap√≥s a cria√ß√£o da tabela, ser√° iniciado um notebook para consulta e visualiza√ß√£o dos dados.

- No explorador de cat√°logo, ap√≥s confirmar a cria√ß√£o da tabela `products`, clique em **Criar** > **Notebook**.
- Verifique se o notebook est√° conectado ao cluster criado anteriormente.
- Execute a c√©lula gerada automaticamente, que recupera os dados da tabela.
- Aguarde a execu√ß√£o e visualize os resultados em formato tabular.

<p align="center">
<img src="images/dados-tabela-sql.png" alt="infobox" width="60%" height="60%"> 
</p>


### 5. Cria√ß√£o de Visualiza√ß√£o Gr√°fica

Para explorar visualmente os dados, adicione uma visualiza√ß√£o do tipo gr√°fico de barras:

- Acima da tabela de resultados, clique em **+** > **Visualiza√ß√£o**
- Configure as op√ß√µes:
  - **Tipo de visualiza√ß√£o:** Bar (barra)
  - **Coluna X:** `Category`
  - **Coluna Y:** `ProductID` com agrega√ß√£o **Count**
- Salve a visualiza√ß√£o.

<p align="center">
<img src="images/visualization-data.png" alt="infobox" width="80%" height="80%"> 
</p>



### 6. An√°lise com PySpark

Para usu√°rios mais experientes com Spark, √© poss√≠vel trabalhar com **dataframes** em Python atrav√©s do m√≥dulo **PySpark**.

- Abaixo da visualiza√ß√£o, clique em **+ C√≥digo** para adicionar uma nova c√©lula.
- Insira o c√≥digo PySpark abaixo para filtrar produtos da categoria ‚ÄúRoad Bikes‚Äù:

```python
 df = spark.sql("SELECT * FROM hive_metastore.default.products")
 df = df.filter("Category == 'Road Bikes'")
 display(df)
```

<p align="center">
<img src="images/pyspark-code.png" alt="infobox" width="60%" height="60%"> 
</p>


### 7. Encerramento dos Recursos

Ao finalizar o uso do ambiente, acesse a aba **Compute**, selecione o cluster `msl-dio-cluster` e clique em **‚ñ† Encerrar** para evitar consumo de recursos.

Para evitar custos adicionais, tamb√©m √© recomend√°vel excluir os recursos criados no Azure, caso n√£o sejam mais necess√°rios.



## üìÑ Arquivo do Notebook

O notebook criado durante o projeto est√° dispon√≠vel neste reposit√≥rio:

üìò [`analise-produtos-spark.ipynb`](./analise-produtos-spark.ipynb)



## üîó Refer√™ncias

* [Explorar o Azure Databricks - Microsoft Learn](https://learn.microsoft.com/pt-br/training/modules/explore-azure-databricks/)
* [Documenta√ß√£o oficial do Azure Databricks](https://learn.microsoft.com/pt-br/azure/databricks/)
* [Azure Databricks Exercises](https://microsoftlearning.github.io/mslearn-databricks/)



---